{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e910c461",
   "metadata": {},
   "source": [
    "# Kernel Calculation Test\n",
    "This notebook is used to test the functionality of the kernel calc methods that (if working) will be rewritten in Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7abf607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources Loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import resources as rs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587053d",
   "metadata": {},
   "source": [
    "### Loading Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a553232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_utils.py:314: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    }
   ],
   "source": [
    "model_path = 'ex_models.pt'\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu')) # MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959e794",
   "metadata": {},
   "source": [
    "### Unpacking the params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008a912",
   "metadata": {},
   "source": [
    "**NOTE:** \n",
    "The model was trained on the MNIST digits of 0 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b480b9",
   "metadata": {},
   "source": [
    "Unpacking the features params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b943de91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0212, -0.0311, -0.0050,  ..., -0.0343, -0.0193,  0.0000],\n",
      "        [ 0.0112, -0.0050,  0.0149,  ..., -0.0093, -0.0106,  0.0336],\n",
      "        [-0.0324, -0.0006, -0.0062,  ...,  0.0311,  0.0137, -0.0324],\n",
      "        ...,\n",
      "        [-0.0305,  0.0168, -0.0293,  ...,  0.0237, -0.0280, -0.0112],\n",
      "        [-0.0349,  0.0056, -0.0174,  ..., -0.0093, -0.0031,  0.0212],\n",
      "        [ 0.0349,  0.0168, -0.0206,  ..., -0.0149,  0.0044, -0.0187]])\n",
      "Parameter containing:\n",
      "tensor([ 0.0235, -0.0103, -0.0210,  ..., -0.0244,  0.0028, -0.0313],\n",
      "       grad_fn=<NotImplemented>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# get the weights and biases of the quantized model (for the features layer)\n",
    "f_weights_quant = state_dict['features.hidden_layer._packed_params._packed_params'][0]\n",
    "f_bias_quant = state_dict['features.hidden_layer._packed_params._packed_params'][1]\n",
    "\n",
    "# dequantize the weights and biases\n",
    "f_weights_float = torch.dequantize(f_weights_quant)\n",
    "f_bias_float = torch.dequantize(f_bias_quant)\n",
    "# print the float values of weights and biases\n",
    "print(f_weights_float)\n",
    "print(f_bias_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db32b1a",
   "metadata": {},
   "source": [
    "Unpacking the readout params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d42817aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0219,  0.0389,  0.0024,  ..., -0.0073,  0.0182, -0.0158],\n",
      "        [-0.0195, -0.0219, -0.0024,  ...,  0.0073, -0.0170,  0.0134]])\n",
      "Parameter containing:\n",
      "tensor([0.4623, 0.4824], grad_fn=<NotImplemented>)\n"
     ]
    }
   ],
   "source": [
    "# get the weights and biases of the quantized model (for the readout layer)\n",
    "r_weights_quant = state_dict['readout._packed_params._packed_params'][0]\n",
    "r_bias_quant = state_dict['readout._packed_params._packed_params'][1]\n",
    "\n",
    "# dequantize the weights and bises\n",
    "r_weights_float = torch.dequantize(r_weights_quant)\n",
    "r_bias_float = torch.dequantize(r_bias_quant)\n",
    "\n",
    "print(r_weights_float)\n",
    "print(r_bias_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6db2f",
   "metadata": {},
   "source": [
    "### Manually updating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e839021f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (features): Sequential(\n",
       "    (hidden_layer): Linear(in_features=784, out_features=2048, bias=True)\n",
       "    (hidden_activation): ReLU()\n",
       "  )\n",
       "  (readout): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rs.NN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab638b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0135, -0.0237,  0.0054,  ...,  0.0342, -0.0247, -0.0317],\n",
       "         [ 0.0325, -0.0190,  0.0209,  ...,  0.0345,  0.0137, -0.0097],\n",
       "         [ 0.0105,  0.0267, -0.0238,  ..., -0.0092,  0.0330,  0.0343],\n",
       "         ...,\n",
       "         [-0.0160,  0.0044, -0.0138,  ..., -0.0175, -0.0025, -0.0057],\n",
       "         [-0.0206,  0.0357,  0.0309,  ..., -0.0236,  0.0310, -0.0297],\n",
       "         [ 0.0049, -0.0330,  0.0098,  ..., -0.0004, -0.0245, -0.0281]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0127, -0.0324, -0.0059,  ...,  0.0179,  0.0112, -0.0176],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0174,  0.0033,  0.0001,  ...,  0.0201, -0.0122, -0.0172],\n",
       "         [ 0.0101,  0.0214,  0.0112,  ..., -0.0177,  0.0167, -0.0195]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0045, 0.0077], requires_grad=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a3a705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params[0].data = f_weights_float\n",
    "params[1].data = f_bias_float\n",
    "params[2].data = r_weights_float\n",
    "params[3].data = r_bias_float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e4324",
   "metadata": {},
   "source": [
    "### Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec70228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "def mnist_dataset(batch_size, train=True, values=list(range(10))):\n",
    "    # Initializing MNIST data set.\n",
    "    dataset = datasets.MNIST(root='dataset/', train=train, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "    targets_list = dataset.targets.tolist()\n",
    "    values_index = [i for i in range(len(dataset)) if targets_list[i] in values]\n",
    "\n",
    "    # Creating a subset of ### MNIST targets.\n",
    "    subset = torch.utils.data.Subset(dataset, values_index)\n",
    "    loader = DataLoader(dataset=subset, shuffle=True)\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4caae1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST = rs.mnist_dataset(batch_size=0, train=True, values=[0,1])\n",
    "data, targets = next(iter(MNIST))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27280bf",
   "metadata": {},
   "source": [
    "Next, in order to perform the CKA calc. we will need to reshape the data into a batch_size X features tenso (12665, 784)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c83b98bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12665, 784])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.squeeze(data, dim=1)\n",
    "data = data.view(data.size(0), -1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b43ea1",
   "metadata": {},
   "source": [
    "### CKA Calc.\n",
    "At this point we can now calculate the CKA for the model state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af095310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12665, 1024])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7189516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12665])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b7f3b6",
   "metadata": {},
   "source": [
    "#TODO using this notebook create a python script that will do this for each of the model states (135 * 512)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ee852",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cef73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a83134d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "loss = nn.MSELoss()\n",
    "model.eval()\n",
    "losses = rs.train(MNIST, device, model, loss, values=[0, 1], backwards=False, record_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "054e4f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.250704013335053e-06"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8f43c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f1677",
   "metadata": {},
   "source": [
    "### CKA Test.\n",
    "Defining Center Kernel Alignment functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ecf2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dd6bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_calc(y, phi):\n",
    "    y = torch.t(torch.unsqueeze(y, -1))\n",
    "    \n",
    "    start = time.time()\n",
    "    K1 = torch.matmul(torch.t(y), y)\n",
    "    \n",
    "    K1c = kernel_centering(K1.float())\n",
    "\n",
    "    K2 = torch.mm(phi, torch.t(phi))\n",
    "    \n",
    "    K2c = kernel_centering(K2)\n",
    "    end = time.time()\n",
    "\n",
    "    return kernel_alignment(K1c, K2c)\n",
    "\n",
    "\n",
    "def frobenius_product(K1, K2):\n",
    "    return torch.sum(K1 * K2)\n",
    "\n",
    "\n",
    "def kernel_alignment(K1, K2):\n",
    "    inner = frobenius_product(K1, K2) \n",
    "    mag_norm = ((torch.norm(K1, p='fro') * torch.norm(K2, p='fro')))\n",
    "    return inner / mag_norm\n",
    "\n",
    "\n",
    "def kernel_centering(K):\n",
    "    row_means = K.mean(dim=1, keepdim=True)\n",
    "    col_means = K.mean(dim=0, keepdim=True)\n",
    "    total_mean = K.mean()\n",
    "    \n",
    "    return K - row_means - col_means + total_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e5d5627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKA : 0.9493693709373474 |TOTAL TIME: 7.698458194732666s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cka = kernel_calc(targets, model.features(data))\n",
    "end = time.time()\n",
    "print(f\"CKA : {cka} |TOTAL TIME: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dcd1ff",
   "metadata": {},
   "source": [
    "### New CKA Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dc164fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/8yd_b2lj50n_j_2v3f_wwvvc0000gn/T/ipykernel_44083/39957181.py:2: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3575.)\n",
      "  y = torch.unsqueeze(targets.T, -1)\n"
     ]
    }
   ],
   "source": [
    "phi = model.features(data)\n",
    "y = torch.unsqueeze(targets.T, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1ad8a",
   "metadata": {},
   "source": [
    "The new methods potentially allows us to ignore the centering calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d2bfdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW METHOD\n",
      "INNER = 406006720.0 | TIME = 0.0041730403900146484s\n"
     ]
    }
   ],
   "source": [
    "# New Method\n",
    "start = time.time()\n",
    "v = phi.T.matmul(y.float())\n",
    "inner = v.T @ v\n",
    "end = time.time()\n",
    "print(\"NEW METHOD\")\n",
    "print(f\"INNER = {inner.item()} | TIME = {end - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc68c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLD METHOD\n",
      "INNER = 406006848.0 | TIME = 58.009095191955566s\n"
     ]
    }
   ],
   "source": [
    "# Old Method\n",
    "start = time.time()\n",
    "K1 = y @ y.T\n",
    "K1 = K1.float()\n",
    "K2 = phi @ phi.T\n",
    "inner = torch.trace(torch.mm(K2, torch.t(K1)))\n",
    "end = time.time()\n",
    "print(\"OLD METHOD\")\n",
    "print(f\"INNER = {inner} | TIME = {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5df06",
   "metadata": {},
   "source": [
    "According to this new finding we can decrease computation time for the frobenius product by 3307.0 multiplier!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec48d259",
   "metadata": {},
   "source": [
    "### Translating this into HSIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31780199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSIC(K1, K2):\n",
    "    num = torch.trace(torch.mm(K2, K1.T))\n",
    "    den = (len(K2) - 1) * (len(K1) - 1)\n",
    "    return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af84b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIC HSIC\n",
      "HSCI = 2.5315794944763184 | TIME = 51.93221092224121s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test = HSIC(K1, K2)\n",
    "end = time.time()\n",
    "print(\"CLASSIC HSIC\")\n",
    "print(f\"HSCI = {test} | TIME = {end - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7176d409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW HSIC\n",
      "NEW HSIC = 2.531578540802002 | TIME = 0.004106044769287109s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "v = phi.T.matmul(y.float())\n",
    "test = v.T @ v / (((len(y) - 1) * (len(phi) - 1)))\n",
    "end = time.time()\n",
    "print(\"NEW HSIC\")\n",
    "print(f\"NEW HSIC = {test.item()} | TIME = {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa945bb",
   "metadata": {},
   "source": [
    "It's of no suprize here that the old methods is much much slower to the same scale as previous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59325ddb",
   "metadata": {},
   "source": [
    "### Implementing This Findining Into CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc30f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cka(y, phi):\n",
    "    \n",
    "    # Centering y\n",
    "    n_y = len(y)\n",
    "    ones_y = torch.ones(n_y, 1)\n",
    "    yc = torch.eye(n_y) - (ones_y @ ones_y.T @ y) / n_y\n",
    "    \n",
    "    # Centering phi\n",
    "    n_phi = len(phi)\n",
    "    ones_phi = torch.ones(n_phi, 1)\n",
    "    phic = torch.eye(n_phi) - (ones_phi @ ones_phi @ y) / n_phi\n",
    "    \n",
    "    # CKA \n",
    "    # Numerator HSIC(K_y, K_phi)\n",
    "    upper = (phic.T @ yc).T @ (phic.T @ yc) / torch.sqrt((n_y - 1)*(n_phi -1))\n",
    "    # Demonerator sqrt(HSIC(K_y, K_y) * HSIC(K_phi, K_phi))\n",
    "    lower = torch.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b3169b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centering y\n",
    "y = y.float()\n",
    "n_y = len(y)\n",
    "ones_y = torch.ones(n_y, 1)\n",
    "yc = torch.eye(n_y) - (ones_y @ ones_y.T @ y) / n_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8c75272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centering phi\n",
    "n_phi = len(phi)\n",
    "ones_phi = torch.ones(n_phi, 1)\n",
    "phic = torch.eye(n_phi) - (ones_phi @ ones_phi.T @ y) / n_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8340bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = (phic.T @ yc).T @ (phic.T @ yc) / torch.sqrt((n_y - 1)*(n_phi -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d33e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = torch.sqrt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
