{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e910c461",
   "metadata": {},
   "source": [
    "# Kernel Calculation Test\n",
    "This notebook is used to test the functionality of the kernel calc methods that (if working) will be rewritten in Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7abf607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources Loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import resources as rs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587053d",
   "metadata": {},
   "source": [
    "### Loading Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a553232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'ex_models.pt'\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu')) # MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959e794",
   "metadata": {},
   "source": [
    "### Unpacking the params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008a912",
   "metadata": {},
   "source": [
    "**NOTE:** \n",
    "The model was trained on the MNIST digits of 0 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b480b9",
   "metadata": {},
   "source": [
    "Unpacking the features params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b943de91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0212, -0.0311, -0.0050,  ..., -0.0343, -0.0193,  0.0000],\n",
      "        [ 0.0112, -0.0050,  0.0149,  ..., -0.0093, -0.0106,  0.0336],\n",
      "        [-0.0324, -0.0006, -0.0062,  ...,  0.0311,  0.0137, -0.0324],\n",
      "        ...,\n",
      "        [-0.0305,  0.0168, -0.0293,  ...,  0.0237, -0.0280, -0.0112],\n",
      "        [-0.0349,  0.0056, -0.0174,  ..., -0.0093, -0.0031,  0.0212],\n",
      "        [ 0.0349,  0.0168, -0.0206,  ..., -0.0149,  0.0044, -0.0187]])\n",
      "Parameter containing:\n",
      "tensor([ 0.0235, -0.0103, -0.0210,  ..., -0.0244,  0.0028, -0.0313],\n",
      "       grad_fn=<NotImplemented>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# get the weights and biases of the quantized model (for the features layer)\n",
    "f_weights_quant = state_dict['features.hidden_layer._packed_params._packed_params'][0]\n",
    "f_bias_quant = state_dict['features.hidden_layer._packed_params._packed_params'][1]\n",
    "\n",
    "# dequantize the weights and biases\n",
    "f_weights_float = torch.dequantize(f_weights_quant)\n",
    "f_bias_float = torch.dequantize(f_bias_quant)\n",
    "# print the float values of weights and biases\n",
    "print(f_weights_float)\n",
    "print(f_bias_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db32b1a",
   "metadata": {},
   "source": [
    "Unpacking the readout params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42817aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0219,  0.0389,  0.0024,  ..., -0.0073,  0.0182, -0.0158],\n",
      "        [-0.0195, -0.0219, -0.0024,  ...,  0.0073, -0.0170,  0.0134]])\n",
      "Parameter containing:\n",
      "tensor([0.4623, 0.4824], grad_fn=<NotImplemented>)\n"
     ]
    }
   ],
   "source": [
    "# get the weights and biases of the quantized model (for the readout layer)\n",
    "r_weights_quant = state_dict['readout._packed_params._packed_params'][0]\n",
    "r_bias_quant = state_dict['readout._packed_params._packed_params'][1]\n",
    "\n",
    "# dequantize the weights and bises\n",
    "r_weights_float = torch.dequantize(r_weights_quant)\n",
    "r_bias_float = torch.dequantize(r_bias_quant)\n",
    "\n",
    "print(r_weights_float)\n",
    "print(r_bias_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6db2f",
   "metadata": {},
   "source": [
    "### Manually updating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e839021f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (features): Sequential(\n",
       "    (hidden_layer): Linear(in_features=784, out_features=2048, bias=True)\n",
       "    (hidden_activation): ReLU()\n",
       "  )\n",
       "  (readout): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rs.NN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab638b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0206, -0.0063, -0.0147,  ..., -0.0132, -0.0048, -0.0265],\n",
       "         [-0.0117, -0.0267, -0.0291,  ..., -0.0133, -0.0140, -0.0113],\n",
       "         [-0.0251, -0.0010, -0.0148,  ...,  0.0110,  0.0352,  0.0148],\n",
       "         ...,\n",
       "         [-0.0261,  0.0334, -0.0274,  ...,  0.0002, -0.0220,  0.0227],\n",
       "         [-0.0134, -0.0297, -0.0057,  ...,  0.0053, -0.0297,  0.0346],\n",
       "         [-0.0099, -0.0183, -0.0262,  ..., -0.0054, -0.0070, -0.0210]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0187, -0.0033,  0.0111,  ...,  0.0338, -0.0140, -0.0327],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0040, -0.0104, -0.0056,  ..., -0.0114,  0.0157, -0.0006],\n",
       "         [ 0.0170, -0.0042, -0.0209,  ...,  0.0210, -0.0009, -0.0077]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0035, -0.0003], requires_grad=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a3a705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params[0].data = f_weights_float\n",
    "params[1].data = f_bias_float\n",
    "params[2].data = r_weights_float\n",
    "params[3].data = r_bias_float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e4324",
   "metadata": {},
   "source": [
    "### Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dec70228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "def mnist_dataset(batch_size, train=True, values=list(range(10))):\n",
    "    # Initializing MNIST data set.\n",
    "    dataset = datasets.MNIST(root='dataset/', train=train, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "    targets_list = dataset.targets.tolist()\n",
    "    values_index = [i for i in range(len(dataset)) if targets_list[i] in values]\n",
    "\n",
    "    # Creating a subset of ### MNIST targets.\n",
    "    subset = torch.utils.data.Subset(dataset, values_index)\n",
    "    loader = DataLoader(dataset=subset, shuffle=True)\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4caae1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST = rs.mnist_dataset(batch_size=0, train=True, values=[0,1])\n",
    "data, targets = next(iter(MNIST))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27280bf",
   "metadata": {},
   "source": [
    "Next, in order to perform the CKA calc. we will need to reshape the data into a batch_size X features tenso (12665, 784)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c83b98bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12665, 784])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.squeeze(data, dim=1)\n",
    "data = data.view(data.size(0), -1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b43ea1",
   "metadata": {},
   "source": [
    "### CKA Calc.\n",
    "At this point we can now calculate the CKA for the model state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af095310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12665, 1024])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7189516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12665])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b7f3b6",
   "metadata": {},
   "source": [
    "#TODO using this notebook create a python script that will do this for each of the model states (135 * 512)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ee852",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cef73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a83134d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "loss = nn.MSELoss()\n",
    "model.eval()\n",
    "losses = rs.train(MNIST, device, model, loss, values=[0, 1], backwards=False, record_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "054e4f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.250704013335053e-06"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8f43c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f1677",
   "metadata": {},
   "source": [
    "### CKA Test.\n",
    "Defining Center Kernel Alignment functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ecf2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6dd6bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_calc(y, phi):\n",
    "    y = torch.t(torch.unsqueeze(y, -1))\n",
    "    \n",
    "    start = time.time()\n",
    "    K1 = torch.matmul(torch.t(y), y)\n",
    "    \n",
    "    K1c = kernel_centering(K1.float())\n",
    "\n",
    "    K2 = torch.mm(phi, torch.t(phi))\n",
    "    \n",
    "    K2c = kernel_centering(K2)\n",
    "    end = time.time()\n",
    "\n",
    "    return kernel_alignment(K1c, K2c)\n",
    "\n",
    "\n",
    "def frobenius_product(K1, K2):\n",
    "    return torch.sum(K1 * K2)\n",
    "\n",
    "\n",
    "def kernel_alignment(K1, K2):\n",
    "    inner = frobenius_product(K1, K2) \n",
    "    mag_norm = ((torch.norm(K1, p='fro') * torch.norm(K2, p='fro')))\n",
    "    print(mag_norm)\n",
    "    return inner / mag_norm\n",
    "\n",
    "\n",
    "def kernel_centering(K):\n",
    "    row_means = K.mean(dim=1, keepdim=True)\n",
    "    col_means = K.mean(dim=0, keepdim=True)\n",
    "    total_mean = K.mean()\n",
    "    \n",
    "    return K - row_means - col_means + total_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1e5d5627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2270e+08, grad_fn=<MulBackward0>)\n",
      "CKA : 0.950365424156189 |TOTAL TIME: 7.190279006958008s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cka = kernel_calc(targets, model.features(data))\n",
    "end = time.time()\n",
    "print(f\"CKA : {cka} |TOTAL TIME: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dcd1ff",
   "metadata": {},
   "source": [
    "### New CKA Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dc164fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38110/39957181.py:2: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525493953/work/aten/src/ATen/native/TensorShape.cpp:3277.)\n",
      "  y = torch.unsqueeze(targets.T, -1)\n"
     ]
    }
   ],
   "source": [
    "phi = model.features(data)\n",
    "y = torch.unsqueeze(targets.T, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1ad8a",
   "metadata": {},
   "source": [
    "The new methods potentially allows us to ignore the centering calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d2bfdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW METHOD\n",
      "INNER = 406006848.0 | TIME = 0.00432586669921875s\n"
     ]
    }
   ],
   "source": [
    "# New Method\n",
    "start = time.time()\n",
    "v = phi.T.matmul(y.float())\n",
    "inner = v.T @ v\n",
    "end = time.time()\n",
    "print(\"NEW METHOD\")\n",
    "print(f\"INNER = {inner.item()} | TIME = {end - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc68c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLD METHOD\n",
      "INNER = 406006848.0 | TIME = 12.153848886489868s\n"
     ]
    }
   ],
   "source": [
    "# Old Method\n",
    "start = time.time()\n",
    "K1 = y @ y.T\n",
    "K1 = K1.float()\n",
    "K2 = phi @ phi.T\n",
    "inner = torch.trace(torch.mm(K2, torch.t(K1)))\n",
    "end = time.time()\n",
    "print(\"OLD METHOD\")\n",
    "print(f\"INNER = {inner} | TIME = {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5df06",
   "metadata": {},
   "source": [
    "According to this new finding we can decrease computation time for the frobenius product by 3307.0 multiplier!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec48d259",
   "metadata": {},
   "source": [
    "### Translating this into HSIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31780199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSIC(K1, K2):\n",
    "    num = torch.trace(torch.mm(K2, K1.T))\n",
    "    den = (len(K2) - 1) * (len(K1) - 1)\n",
    "    return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af84b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIC HSIC\n",
      "HSCI = 2.5315794944763184 | TIME = 10.108643054962158s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test = HSIC(K1, K2)\n",
    "end = time.time()\n",
    "print(\"CLASSIC HSIC\")\n",
    "print(f\"HSCI = {test} | TIME = {end - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7176d409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW HSIC\n",
      "NEW HSIC = 2.5315794944763184 | TIME = 0.0043621063232421875s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "v = phi.T.matmul(y.float())\n",
    "test = v.T @ v / (((len(y) - 1) * (len(phi) - 1)))\n",
    "end = time.time()\n",
    "print(\"NEW HSIC\")\n",
    "print(f\"NEW HSIC = {test.item()} | TIME = {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa945bb",
   "metadata": {},
   "source": [
    "It's of no suprize here that the old methods is much much slower to the same scale as previous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59325ddb",
   "metadata": {},
   "source": [
    "### Implementing This Findining Into CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc30f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cka(y, phi):\n",
    "    \n",
    "    # Centering y\n",
    "    n_y = len(y)\n",
    "    ones_y = torch.ones(n_y, 1)\n",
    "    yc = torch.eye(n_y) - (ones_y @ ones_y.T @ y) / n_y\n",
    "    \n",
    "    # Centering phi\n",
    "    n_phi = len(phi)\n",
    "    ones_phi = torch.ones(n_phi, 1)\n",
    "    phic = torch.eye(n_phi) - (ones_phi @ ones_phi @ y) / n_phi\n",
    "    \n",
    "    # CKA \n",
    "    # Numerator HSIC(K_y, K_phi)\n",
    "    upper = (phic.T @ yc).T @ (phic.T @ yc) / torch.sqrt((n_y - 1)*(n_phi -1))\n",
    "    # Demonerator sqrt(HSIC(K_y, K_y) * HSIC(K_phi, K_phi))\n",
    "    lower = torch.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9c92074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centering y\n",
    "y = y.float()\n",
    "n_y = len(y)\n",
    "ones_y = torch.ones(n_y, 1)\n",
    "yc = torch.ones([12665, 1]) - (ones_y @ ones_y.T @ y) / n_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b8c75272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centering phi\n",
    "n_phi = len(phi)\n",
    "ones_phi = torch.ones(n_phi, 1)\n",
    "phic = torch.eye(n_phi) - (ones_phi @ ones_phi.T @ y) / n_phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46819675",
   "metadata": {},
   "source": [
    "### Creating CKA function with this new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4c9090df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9c3bdc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = phic.T.matmul(yc)\n",
    "u = (v.T @ v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7e6d0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1.2270e+08\n",
    "cka = u / d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ab77d920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1025.8938]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e7ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
