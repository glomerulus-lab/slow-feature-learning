{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48536bc4",
   "metadata": {},
   "source": [
    "Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c09eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn   # Nueral network modules.\n",
    "from collections import OrderedDict\n",
    "import torch  # Base torch library\n",
    "from torch.utils.data import DataLoader  # Minibathces\n",
    "import torchvision.datasets as datasets  # MNIST dataset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn  # Neural network modules\n",
    "import torch.optim as optim  # Optimization algorithms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eae84d",
   "metadata": {},
   "source": [
    "Model Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa66858",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, middle_width, num_classes):\n",
    "\n",
    "\n",
    "        super(NN, self).__init__()\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('hidden_layer', nn.Linear(input_size, middle_width)),\n",
    "            ('hidden_activation', nn.ReLU()),\n",
    "        ]))\n",
    "        self.readout = nn.Linear(middle_width, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.readout(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f244dba",
   "metadata": {},
   "source": [
    "Network Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b5a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    return device\n",
    "\n",
    "\n",
    "def mnist_dataset(batch_size, train=True, values=list(range(10))):\n",
    "    # Initializing MNIST data set.\n",
    "    dataset = datasets.MNIST(root='dataset/', train=train, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "    targets_list = dataset.targets.tolist()\n",
    "    values_index = [i for i in range(len(dataset)) if targets_list[i] in values]\n",
    "\n",
    "    # Creating a subset of ### MNIST targets.\n",
    "    subset = torch.utils.data.Subset(dataset, values_index)\n",
    "    loader = DataLoader(dataset=subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def train(loader, device, model, loss_function, optimizer_function, values=list(range(10))):\n",
    "    # Training on each data point.\n",
    "    for batch_idx, (data, targets) in enumerate(loader):\n",
    "        data = data.reshape(data.shape[0], -1).to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # Forwards.\n",
    "        scores = model(data)\n",
    "        loss = loss_function(scores, classify_targets(targets, values))\n",
    "\n",
    "        # Backwards.\n",
    "        optimizer_function.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer_function.step()\n",
    "        \n",
    "        \n",
    "        phi = slow_model.features(data)\n",
    "        \n",
    "        return targets, phi\n",
    "\n",
    "\n",
    "def record_accuracy(device, model, train_loader, test_loader, epoch, values=list(range(10))):\n",
    "    epoch_accuracy = np.array([[\n",
    "        epoch + 1,\n",
    "        check_accuracy(device, model, train_loader, values).cpu(),\n",
    "        check_accuracy(device, model, test_loader, values).cpu()\n",
    "    ]])\n",
    "\n",
    "    return epoch_accuracy\n",
    "\n",
    "\n",
    "def check_accuracy(device, model, loader, values=list(range(10))):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = classify_targets(y, values).to(device=device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            scores = model(x)\n",
    "            # 64images x 10,\n",
    "\n",
    "            predictions = scores.argmax(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    return 100 - 100. * num_correct / num_samples\n",
    "\n",
    "\n",
    "def classify_targets(targets, values):\n",
    "    new_targets = targets.clone()\n",
    "\n",
    "    # Changing targets to a classifiable number.\n",
    "    for key, element in enumerate(values):\n",
    "        new_targets[targets == element] = key\n",
    "    return new_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290531f8",
   "metadata": {},
   "source": [
    "Main Program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a295a057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n",
      "Hyper Parameters: {'Input Size': 784, 'Middle Layer Width': 2000, 'Num Classes': 2, 'Regular Learning Rate': 0.01, 'Slow Learning Rate': 0.001, 'Batch Size': 200, 'Epochs': 1}\n",
      "MNIST digits [8, 9]\n",
      "Training models...\n",
      "Slow: \n",
      "[[ 1.         45.44067764 46.39435196]]\n",
      "Reg: \n",
      "[[ 1.         34.95762634 31.97176361]]\n",
      "-Finished epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "# Checking & Setting Device Allocation\n",
    "device = set_device()\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "# Hyper Parameters\n",
    "hp = {\n",
    "    \"Input Size\": 784,\n",
    "    \"Middle Layer Width\": 2000,\n",
    "    \"Num Classes\": 2,\n",
    "    \"Regular Learning Rate\": 0.01,\n",
    "    \"Slow Learning Rate\": 0.001,\n",
    "    \"Batch Size\": 200,\n",
    "    \"Epochs\": 1\n",
    "}\n",
    "print(f\"Hyper Parameters: {hp}\")\n",
    "\n",
    "# Initializing Model\n",
    "slow_model = NN(input_size=hp[\"Input Size\"],\n",
    "                middle_width=hp[\"Middle Layer Width\"],\n",
    "                num_classes=hp[\"Num Classes\"]).to(device=device)\n",
    "\n",
    "reg_model = NN(input_size=hp[\"Input Size\"],\n",
    "               middle_width=hp[\"Middle Layer Width\"],\n",
    "               num_classes=hp[\"Num Classes\"]).to(device=device)\n",
    "\n",
    "# Loading MNIST Dataset\n",
    "mnist_values = [8, 9]\n",
    "print(f\"MNIST digits {mnist_values}\")\n",
    "train_loader = mnist_dataset(hp[\"Batch Size\"], values=mnist_values)\n",
    "validate_loader = mnist_dataset(hp[\"Batch Size\"], train=False, values=mnist_values)\n",
    "\n",
    "# Loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers\n",
    "sl_optimizer = optim.SGD([{'params': slow_model.features.hidden_layer.parameters()},\n",
    "                          {'params': slow_model.readout.parameters(),\n",
    "                           'lr': hp[\"Regular Learning Rate\"]}],\n",
    "                         lr=hp[\"Slow Learning Rate\"])\n",
    "r_optimizer = optim.SGD(reg_model.parameters(), lr=hp[\"Regular Learning Rate\"])\n",
    "\n",
    "# Creating 'empty' arrays for future storing of accuracy metrics\n",
    "slow_accuracy = np.zeros((1, 3))\n",
    "regular_accuracy = np.zeros((1, 3))\n",
    "\n",
    "print(\"Training models...\")\n",
    "for epoch in range(hp[\"Epochs\"]):\n",
    "\n",
    "    # Slow Model\n",
    "    sl_targets, sl_phi = train(train_loader, device, slow_model, loss_function, sl_optimizer, values=mnist_values)\n",
    "    slow_accuracy_epoch = record_accuracy(device, slow_model, train_loader, validate_loader, epoch, mnist_values)\n",
    "    slow_accuracy = np.concatenate((slow_accuracy, slow_accuracy_epoch))\n",
    "    print(\"Slow: \")\n",
    "    print(slow_accuracy_epoch)\n",
    "    # Regular Model\n",
    "    reg_targets, reg_phi = train(train_loader, device, reg_model, loss_function, r_optimizer, values=mnist_values)\n",
    "    regular_accuracy_epoch = record_accuracy(device, reg_model, train_loader, validate_loader, epoch, mnist_values)\n",
    "    regular_accuracy = np.concatenate((regular_accuracy, regular_accuracy_epoch))\n",
    "    print(\"Reg: \")\n",
    "    print(regular_accuracy_epoch)\n",
    "    print(f\"-Finished epoch {epoch + 1}/{hp['Epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc3b5c",
   "metadata": {},
   "source": [
    "***\n",
    "Kernel Alignment Calc:\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1cb945",
   "metadata": {},
   "source": [
    "Kernel Matrix: $K_{1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08109773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones(vector):\n",
    "    for i in range(vector.size()[1]):\n",
    "        if vector[0][i] == 9:\n",
    "            vector[0][i] = int(1)\n",
    "        elif vector[0][i] == 8:\n",
    "            vector[0][i] = int(-1)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3588c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_targets = torch.t(torch.unsqueeze(sl_targets, -1))\n",
    "sl_targets = ones(sl_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f491e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = torch.matmul(torch.t(sl_targets), sl_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be4cac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 200]),\n",
       " tensor([[ 1,  1, -1,  ..., -1, -1,  1],\n",
       "         [ 1,  1, -1,  ..., -1, -1,  1],\n",
       "         [-1, -1,  1,  ...,  1,  1, -1],\n",
       "         ...,\n",
       "         [-1, -1,  1,  ...,  1,  1, -1],\n",
       "         [-1, -1,  1,  ...,  1,  1, -1],\n",
       "         [ 1,  1, -1,  ..., -1, -1,  1]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K1.size(), K1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d423b968",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac5751",
   "metadata": {},
   "source": [
    "Kernel Matrix: $K_{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc088650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_model.features.hidden_activation.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba04d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = sl_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a0c5393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 200]),\n",
       " tensor([[33.1187, 21.5473, 20.9343,  ..., 21.7796, 30.2600, 21.1120],\n",
       "         [21.5473, 29.0505, 18.4541,  ..., 17.9103, 24.5469, 20.4648],\n",
       "         [20.9343, 18.4541, 31.0415,  ..., 22.6074, 28.3908, 21.1280],\n",
       "         ...,\n",
       "         [21.7796, 17.9103, 22.6074,  ..., 37.2730, 31.2093, 28.2651],\n",
       "         [30.2600, 24.5469, 28.3908,  ..., 31.2093, 55.9216, 33.0817],\n",
       "         [21.1120, 20.4648, 21.1280,  ..., 28.2651, 33.0817, 40.1273]],\n",
       "        grad_fn=<MmBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K2 = torch.mm(phi, torch.t(phi))\n",
    "K2.size(), K2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c22ea",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53c984",
   "metadata": {},
   "source": [
    "Kernel Centering: \n",
    "\n",
    "$K_{c} = \\left[ I - \\frac{11^{T}}{m} \\right] K \\left[ I - \\frac{11^{T}}{m} \\right]$\n",
    "\n",
    "*Note: let 1 denote the vector with all enteries equal to one and I being the identity matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a949ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_centering(K):\n",
    "    # Lemmna 1\n",
    "    \n",
    "    m = K.size()[0]\n",
    "    I = torch.eye(m)\n",
    "    l = torch.ones(m, 1)\n",
    "    \n",
    "    # I - ll^T / m\n",
    "    mat = I - torch.matmul(l, torch.t(l))/m\n",
    "    \n",
    "    \n",
    "    return torch.matmul(torch.matmul(mat, K), mat)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fbbd6",
   "metadata": {},
   "source": [
    "Centering Kernel $K_{1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7957ec85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0000,  1.0000, -1.0000,  ..., -1.0000, -1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000, -1.0000,  ..., -1.0000, -1.0000,  1.0000],\n",
       "         [-1.0000, -1.0000,  1.0000,  ...,  1.0000,  1.0000, -1.0000],\n",
       "         ...,\n",
       "         [-1.0000, -1.0000,  1.0000,  ...,  1.0000,  1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000,  1.0000,  ...,  1.0000,  1.0000, -1.0000],\n",
       "         [ 1.0000,  1.0000, -1.0000,  ..., -1.0000, -1.0000,  1.0000]]),\n",
       " torch.Size([200, 200]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kc1 = kernel_centering(K1.float())\n",
    "Kc1, Kc1.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51939ee3",
   "metadata": {},
   "source": [
    "Centering Kernel $K_{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee5baecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[11.0227,  2.2952,  0.9036,  ..., -1.9539,  0.2343, -3.0256],\n",
       "         [ 2.2952, 12.6422,  1.2672,  ..., -2.9793, -2.6350, -0.8291],\n",
       "         [ 0.9036,  1.2672, 13.0759,  ...,  0.9391,  0.4302, -0.9445],\n",
       "         ...,\n",
       "         [-1.9539, -2.9793,  0.9391,  ..., 11.9020, -0.4540,  2.4899],\n",
       "         [ 0.2343, -2.6350,  0.4302,  ..., -0.4540, 17.9661,  1.0142],\n",
       "         [-3.0256, -0.8291, -0.9445,  ...,  2.4899,  1.0142, 13.9478]],\n",
       "        grad_fn=<MmBackward0>),\n",
       " torch.Size([200, 200]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kc2 = kernel_centering(K2)\n",
    "Kc2, Kc2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb98d7f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c327c80",
   "metadata": {},
   "source": [
    "Kernel Aligment Function: $\\hat{p}(K, K') = \\frac{\\langle K_{c}, K_{c}' \\rangle}{\\| K_{c} \\| \\| K_{c}' \\|} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eb9da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_product(K1, K2):\n",
    "    return torch.trace(torch.mm(K2, torch.t(K1)))\n",
    "\n",
    "def kernel_alignment(K1, K2):\n",
    "    return frobenius_product(K1, K2)/((torch.norm(K1, p='fro')*torch.norm(K2, p='fro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a8d3542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45735299587249756"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_alignment(Kc1, Kc2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48c847ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acf733b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f5d5e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((300, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03c0ee4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slow-feature-learning",
   "language": "python",
   "name": "slow-feature-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
