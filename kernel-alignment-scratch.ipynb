{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48536bc4",
   "metadata": {},
   "source": [
    "Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c09eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn   # Nueral network modules.\n",
    "from collections import OrderedDict\n",
    "import torch  # Base torch library\n",
    "from torch.utils.data import DataLoader  # Minibathces\n",
    "import torchvision.datasets as datasets  # MNIST dataset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn  # Neural network modules\n",
    "import torch.optim as optim  # Optimization algorithms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eae84d",
   "metadata": {},
   "source": [
    "Model Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aa66858",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, middle_width, num_classes):\n",
    "\n",
    "\n",
    "        super(NN, self).__init__()\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('hidden_layer', nn.Linear(input_size, middle_width)),\n",
    "            ('hidden_activation', nn.ReLU()),\n",
    "        ]))\n",
    "        self.readout = nn.Linear(middle_width, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.readout(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f244dba",
   "metadata": {},
   "source": [
    "Network Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59b5a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    return device\n",
    "\n",
    "\n",
    "def mnist_dataset(batch_size, train=True, values=list(range(10))):\n",
    "    # Initializing MNIST data set.\n",
    "    dataset = datasets.MNIST(root='dataset/', train=train, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "    targets_list = dataset.targets.tolist()\n",
    "    values_index = [i for i in range(len(dataset)) if targets_list[i] in values]\n",
    "\n",
    "    # Creating a subset of ### MNIST targets.\n",
    "    subset = torch.utils.data.Subset(dataset, values_index)\n",
    "    loader = DataLoader(dataset=subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def train(loader, device, model, loss_function, optimizer_function, values=list(range(10))):\n",
    "    # Training on each data point.\n",
    "    for batch_idx, (data, targets) in enumerate(loader):\n",
    "        data = data.reshape(data.shape[0], -1).to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # Forwards.\n",
    "        scores = model(data)\n",
    "        loss = loss_function(scores, classify_targets(targets, values))\n",
    "\n",
    "        # Backwards.\n",
    "        optimizer_function.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer_function.step()\n",
    "        \n",
    "        \n",
    "        phi = slow_model.features(data)\n",
    "        \n",
    "        return targets, phi\n",
    "\n",
    "\n",
    "def record_accuracy(device, model, train_loader, test_loader, epoch, values=list(range(10))):\n",
    "    epoch_accuracy = np.array([[\n",
    "        epoch + 1,\n",
    "        check_accuracy(device, model, train_loader, values).cpu(),\n",
    "        check_accuracy(device, model, test_loader, values).cpu()\n",
    "    ]])\n",
    "\n",
    "    return epoch_accuracy\n",
    "\n",
    "\n",
    "def check_accuracy(device, model, loader, values=list(range(10))):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = classify_targets(y, values).to(device=device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            scores = model(x)\n",
    "            # 64images x 10,\n",
    "\n",
    "            predictions = scores.argmax(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    return 100 - 100. * num_correct / num_samples\n",
    "\n",
    "\n",
    "def classify_targets(targets, values):\n",
    "    new_targets = targets.clone()\n",
    "\n",
    "    # Changing targets to a classifiable number.\n",
    "    for key, element in enumerate(values):\n",
    "        new_targets[targets == element] = key\n",
    "    return new_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290531f8",
   "metadata": {},
   "source": [
    "Main Program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a295a057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n",
      "Hyper Parameters: {'Input Size': 784, 'Middle Layer Width': 2000, 'Num Classes': 2, 'Regular Learning Rate': 0.01, 'Slow Learning Rate': 0.001, 'Batch Size': 200, 'Epochs': 1}\n",
      "MNIST digits [8, 9]\n",
      "Training models...\n",
      "Slow: \n",
      "[[ 1.         50.26271057 50.78164291]]\n",
      "Reg: \n",
      "[[ 1.         34.16949463 31.46747589]]\n",
      "-Finished epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "# Checking & Setting Device Allocation\n",
    "device = set_device()\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "# Hyper Parameters\n",
    "hp = {\n",
    "    \"Input Size\": 784,\n",
    "    \"Middle Layer Width\": 2000,\n",
    "    \"Num Classes\": 2,\n",
    "    \"Regular Learning Rate\": 0.01,\n",
    "    \"Slow Learning Rate\": 0.001,\n",
    "    \"Batch Size\": 200,\n",
    "    \"Epochs\": 1\n",
    "}\n",
    "print(f\"Hyper Parameters: {hp}\")\n",
    "\n",
    "# Initializing Model\n",
    "slow_model = NN(input_size=hp[\"Input Size\"],\n",
    "                middle_width=hp[\"Middle Layer Width\"],\n",
    "                num_classes=hp[\"Num Classes\"]).to(device=device)\n",
    "\n",
    "reg_model = NN(input_size=hp[\"Input Size\"],\n",
    "               middle_width=hp[\"Middle Layer Width\"],\n",
    "               num_classes=hp[\"Num Classes\"]).to(device=device)\n",
    "\n",
    "# Loading MNIST Dataset\n",
    "mnist_values = [8, 9]\n",
    "print(f\"MNIST digits {mnist_values}\")\n",
    "train_loader = mnist_dataset(hp[\"Batch Size\"], values=mnist_values)\n",
    "validate_loader = mnist_dataset(hp[\"Batch Size\"], train=False, values=mnist_values)\n",
    "\n",
    "# Loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers\n",
    "sl_optimizer = optim.SGD([{'params': slow_model.features.hidden_layer.parameters()},\n",
    "                          {'params': slow_model.readout.parameters(),\n",
    "                           'lr': hp[\"Regular Learning Rate\"]}],\n",
    "                         lr=hp[\"Slow Learning Rate\"])\n",
    "r_optimizer = optim.SGD(reg_model.parameters(), lr=hp[\"Regular Learning Rate\"])\n",
    "\n",
    "# Creating 'empty' arrays for future storing of accuracy metrics\n",
    "slow_accuracy = np.zeros((1, 3))\n",
    "regular_accuracy = np.zeros((1, 3))\n",
    "\n",
    "print(\"Training models...\")\n",
    "for epoch in range(hp[\"Epochs\"]):\n",
    "\n",
    "    # Slow Model\n",
    "    sl_targets, sl_phi = train(train_loader, device, slow_model, loss_function, sl_optimizer, values=mnist_values)\n",
    "    slow_accuracy_epoch = record_accuracy(device, slow_model, train_loader, validate_loader, epoch, mnist_values)\n",
    "    slow_accuracy = np.concatenate((slow_accuracy, slow_accuracy_epoch))\n",
    "    print(\"Slow: \")\n",
    "    print(slow_accuracy_epoch)\n",
    "    # Regular Model\n",
    "    reg_targets, reg_phi = train(train_loader, device, reg_model, loss_function, r_optimizer, values=mnist_values)\n",
    "    regular_accuracy_epoch = record_accuracy(device, reg_model, train_loader, validate_loader, epoch, mnist_values)\n",
    "    regular_accuracy = np.concatenate((regular_accuracy, regular_accuracy_epoch))\n",
    "    print(\"Reg: \")\n",
    "    print(regular_accuracy_epoch)\n",
    "    print(f\"-Finished epoch {epoch + 1}/{hp['Epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc3b5c",
   "metadata": {},
   "source": [
    "***\n",
    "Kernel Alignment Calc:\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1cb945",
   "metadata": {},
   "source": [
    "Kernel Matrix: $K_{1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44de28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_targets = torch.t(torch.unsqueeze(sl_targets, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cee6962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 8, 9, 8, 9, 9, 8, 9, 9, 9, 8, 9, 8, 9, 8, 8, 8, 9, 9, 8, 8, 8, 8, 8,\n",
       "         9, 8, 8, 9, 9, 9, 8, 9, 9, 8, 9, 8, 9, 8, 8, 9, 8, 8, 9, 8, 9, 9, 9, 9,\n",
       "         8, 8, 8, 9, 9, 8, 8, 9, 9, 9, 8, 9, 8, 8, 8, 9, 8, 8, 9, 8, 9, 8, 9, 9,\n",
       "         9, 8, 9, 9, 8, 9, 8, 8, 9, 8, 9, 8, 8, 8, 8, 9, 8, 9, 9, 8, 9, 8, 9, 9,\n",
       "         8, 8, 9, 8, 8, 9, 8, 9, 8, 8, 8, 8, 9, 9, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9,\n",
       "         8, 8, 8, 8, 8, 8, 8, 9, 9, 8, 8, 9, 8, 9, 9, 8, 8, 9, 8, 8, 8, 8, 8, 9,\n",
       "         8, 9, 8, 8, 8, 8, 9, 9, 9, 8, 8, 8, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 9, 8,\n",
       "         8, 8, 8, 9, 8, 8, 8, 8, 8, 9, 9, 8, 9, 9, 9, 8, 8, 8, 8, 9, 8, 8, 9, 8,\n",
       "         8, 9, 8, 8, 9, 8, 9, 9]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08109773",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(sl_targets.size()[0]):\n",
    "    if sl_targets[0][i] == 9:\n",
    "        sl_targets[i] = int(1)\n",
    "    else:\n",
    "        sl_targets[i] = int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f491e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = torch.matmul(torch.t(sl_targets), sl_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8be4cac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 200])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K1.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d423b968",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac5751",
   "metadata": {},
   "source": [
    "Kernel Matrix: $K_{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc088650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_model.features.hidden_activation.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba04d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = sl_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a0c5393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 200])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K2 = torch.matmul(phi, torch.t(phi))\n",
    "K2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c22ea",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53c984",
   "metadata": {},
   "source": [
    "Kernel Centering: \n",
    "\n",
    "$K_{c} = \\left[ I - \\frac{11^{T}}{m} \\right] K \\left[ I - \\frac{11^{T}}{m} \\right]$\n",
    "\n",
    "*Note: let 1 denote the vector with all enteries equal to one and I being the identity matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a949ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_centering(K):\n",
    "    # Lemmna 1\n",
    "    \n",
    "    m = K.size()[0]\n",
    "    I = torch.eye(m)\n",
    "    l = torch.ones(m, 1)\n",
    "    \n",
    "    # I - ll^T / m\n",
    "    mat = I - torch.matmul(l, torch.t(l))/m\n",
    "    \n",
    "    \n",
    "    return torch.matmul(torch.matmul(mat, K), mat)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fbbd6",
   "metadata": {},
   "source": [
    "Centering Kernel $K_{1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7957ec85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.9992e-10,  2.9992e-10,  2.9986e-10,  ..., -7.1516e-09,\n",
       "          -7.1516e-09, -7.1516e-09],\n",
       "         [ 2.9992e-10,  2.9992e-10,  2.9986e-10,  ..., -7.1516e-09,\n",
       "          -7.1516e-09, -7.1516e-09],\n",
       "         [ 2.9992e-10,  2.9992e-10,  2.9986e-10,  ..., -7.1516e-09,\n",
       "          -7.1516e-09, -7.1516e-09],\n",
       "         ...,\n",
       "         [ 3.2056e-09,  3.2056e-09,  3.2055e-09,  ..., -7.6889e-08,\n",
       "          -7.6889e-08, -7.6889e-08],\n",
       "         [ 3.3889e-09,  3.3889e-09,  3.3890e-09,  ..., -8.1361e-08,\n",
       "          -8.1361e-08, -8.1361e-08],\n",
       "         [ 3.5778e-09,  3.5778e-09,  3.5778e-09,  ..., -8.5831e-08,\n",
       "          -8.5831e-08, -8.5831e-08]]),\n",
       " torch.Size([200, 200]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kc1 = kernel_centering(K1.float())\n",
    "Kc1, Kc1.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51939ee3",
   "metadata": {},
   "source": [
    "Centering Kernel $K_{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee5baecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10.5177,  1.9631, -2.7707,  ...,  0.6664, -1.9902, -2.7594],\n",
       "         [ 1.9631, 11.3822, -3.6263,  ..., -0.9451, -2.3427, -2.7076],\n",
       "         [-2.7707, -3.6263, 21.7066,  ...,  5.0532,  8.1675, 10.0201],\n",
       "         ...,\n",
       "         [ 0.6664, -0.9450,  5.0532,  ..., 13.3286,  1.3345,  1.7989],\n",
       "         [-1.9902, -2.3427,  8.1675,  ...,  1.3345, 20.5117,  8.7552],\n",
       "         [-2.7594, -2.7076, 10.0201,  ...,  1.7989,  8.7552, 25.7633]],\n",
       "        grad_fn=<MmBackward0>),\n",
       " torch.Size([200, 200]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kc2 = kernel_centering(K2)\n",
    "Kc2, Kc2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb98d7f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c327c80",
   "metadata": {},
   "source": [
    "Kernel Aligment Function: $\\hat{p}(K, K') = \\frac{\\langle K_{c}, K_{c}' \\rangle}{\\| K_{c} \\| \\| K_{c}' \\|} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0eb9da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_alignment(K1, K2):\n",
    "    return torch.mm(K1, K2)/(torch.norm(K1, p='fro')*torch.norm(K2, p='fro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69a180fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.5761e-05,  8.4785e-05, -1.5062e-04,  ..., -1.1316e-04,\n",
       "         -2.3778e-04, -2.6700e-04],\n",
       "        [ 4.5761e-05,  8.4785e-05, -1.5062e-04,  ..., -1.1316e-04,\n",
       "         -2.3778e-04, -2.6700e-04],\n",
       "        [ 4.5761e-05,  8.4785e-05, -1.5062e-04,  ..., -1.1316e-04,\n",
       "         -2.3778e-04, -2.6700e-04],\n",
       "        ...,\n",
       "        [ 4.9179e-04,  9.1129e-04, -1.6191e-03,  ..., -1.2164e-03,\n",
       "         -2.5561e-03, -2.8701e-03],\n",
       "        [ 5.2035e-04,  9.6424e-04, -1.7133e-03,  ..., -1.2871e-03,\n",
       "         -2.7047e-03, -3.0369e-03],\n",
       "        [ 5.4898e-04,  1.0173e-03, -1.8074e-03,  ..., -1.3579e-03,\n",
       "         -2.8533e-03, -3.2038e-03]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_alignment(Kc1, Kc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47d3b3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.6182e-06), tensor(567.4170, grad_fn=<CopyBackwards>))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(Kc1, p='fro'), torch.norm(Kc2, p='fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29f3d563",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mm() got an unexpected keyword argument 'p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: mm() got an unexpected keyword argument 'p'"
     ]
    }
   ],
   "source": [
    "torch.mm(Kc1, Kc2, p ='fro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slow-feature-learning",
   "language": "python",
   "name": "slow-feature-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
